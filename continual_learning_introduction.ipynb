{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning\n",
    "### La (necessaria) rivoluzione del Machine Learning\n",
    "\n",
    "\n",
    "##### Machine Learning Journal Club - https://www.mljc.it/\n",
    "##### Luca Bottero - luca.bottero192@edu.unito.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Motivazioni\n",
    "\n",
    "E' un fatto ben noto che il Machine Learning è in grado di fornire una soluzione a problemi computazionalmente estremamente complessi\n",
    "con risultati stupefacenti (a volte superando il benchmark umano di riferimento). Il ML è *de facto* lo standard per molte applicazioni\n",
    "di grande interesse industriale e di consumo, in un contesto di forte crescita sia della qualità dei risultati sia della quantità di \n",
    "scenari dove la sua applicazione risulta vantaggiosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Vision\n",
    "Tra i risultati più notevoli del ML vi è sicuramente il suo impiego come strumento di Machine Vision: nella sua forma più elementare, un'immagine (matrice\n",
    "di intensità del segnale sui pixel) viene classificata all'interno di un insieme **finito e determinato** di categorie. Adottando modelli più complessi \n",
    "è possibile ottenere il cosidetto \"Masking\" (classificazione di determinate aree dell'immagine come appartenenti a specifiche oggetti), fino ad arrivare alla\n",
    "\"Image Caption Generation\", alla \"Image Question Answering\" e ad altro ancora.\n",
    "\n",
    "Lavorare con le immagini presenta diverse difficoltà, in primis le dimensioni dei dataset ($ O(10^2) $ GB per ImageNet) e il grande carico computazionale\n",
    "dei modelli impiegati (che possono facilmente superare le decine di ore su hardware specializzato). Esistono anche problematiche etiche e legali, che tuttavia\n",
    "non discutiamo.\n",
    "\n",
    "Per ovviare a tali problemi, si può fare ricorso a un dataset dalle dimensioni contenute. La scelta standard in tal senso è il dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "random_seed = 42\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "print(example_data.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  fig.set_facecolor('white')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immaginiamo ora la seguente situazione: è necessario sviluppare un modello che riconosca la differenza tra le cifre 0 e 1. Dato che si tratta di un problema piuttosto semplice, decidiamo di costruire una rete neurale multistrato semplice, un percettrone. Impostiamo i dataloader, creiamo un modello e verifichiamo l'efficiacia del nostro approccio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5923, 1])\n",
      "torch.Size([6742, 1])\n",
      "torch.Size([12665, 1])\n",
      "torch.Size([980, 1])\n",
      "torch.Size([1135, 1])\n",
      "torch.Size([2115, 1])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "idx_0 = train_dataset.targets == 0\n",
    "idx_1 = train_dataset.targets == 1\n",
    "\n",
    "idx = idx_0 | idx_1\n",
    "\n",
    "print(idx_0.nonzero().shape)\n",
    "print(idx_1.nonzero().shape)\n",
    "print(idx.nonzero().shape)\n",
    "\n",
    "train_dataset_01 = copy.deepcopy(train_dataset)\n",
    "train_dataset_01.targets = train_dataset_01.targets[idx]\n",
    "train_dataset_01.data = train_dataset_01.data[idx]\n",
    "\n",
    "train_loader_01 = torch.utils.data.DataLoader(train_dataset_01, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "idx_0 = test_dataset.targets == 0\n",
    "idx_1 = test_dataset.targets == 1\n",
    "\n",
    "idx = idx_0 | idx_1\n",
    "\n",
    "print(idx_0.nonzero().shape)\n",
    "print(idx_1.nonzero().shape)\n",
    "print(idx.nonzero().shape)\n",
    "\n",
    "test_dataset_01 = copy.deepcopy(test_dataset)\n",
    "test_dataset_01.targets = test_dataset_01.targets[idx]\n",
    "test_dataset_01.data = test_dataset_01.data[idx]\n",
    "\n",
    "test_loader_01 = torch.utils.data.DataLoader(test_dataset_01, batch_size=batch_size_test, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'operazione sopra poteva essere svolta in modo leggermente più rapido, tuttavia è evidente che il processo è piuttosto macchinoso. La rete neurale è definita come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x1 = F.relu(x)\n",
    "        x = self.fc2(x1)\n",
    "        x2 = F.relu(x)\n",
    "\n",
    "        return F.log_softmax(self.fc3(x2), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nostro modello elementare ha due layer e ha la funzione ReLu come attivazione. Dato che si tratta di un problema di classificazone, usiamo log_softmax come funzione di penalizzazione.\n",
    "Definiamo ora le funzioni per eseguire l'allenamento e la valutazione del nostro modello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    #model.train()\n",
    "\n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        mean_loss = 0\n",
    "        for num_tepoch, (data, target) in enumerate(tepoch):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            mean_loss += loss.item()\n",
    "\n",
    "            tepoch.set_postfix(loss=mean_loss/(num_tepoch + 1))\n",
    "        \n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    return((test_loss, 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "use_cuda = False\n",
    "save_model  = True\n",
    "epochs      = 5\n",
    "lr          = 1e-2\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "model_01 = SimpleNet().to(device)\n",
    "\n",
    "optimizer = optim.Adadelta(model_01.parameters(), lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:02<00:00, 69.33batch/s, loss=0.658]\n",
      "  5%|▍         | 9/198 [00:00<00:02, 80.09batch/s, loss=0.603]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6079, Accuracy: 2100/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:02<00:00, 76.00batch/s, loss=0.55] \n",
      "  4%|▍         | 8/198 [00:00<00:02, 73.98batch/s, loss=0.493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4923, Accuracy: 2093/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:02<00:00, 78.26batch/s, loss=0.441]\n",
      "  4%|▍         | 8/198 [00:00<00:02, 77.17batch/s, loss=0.382]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3786, Accuracy: 2093/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:02<00:00, 73.38batch/s, loss=0.331]\n",
      "  4%|▎         | 7/198 [00:00<00:03, 63.22batch/s, loss=0.274]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2761, Accuracy: 2099/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:03<00:00, 64.69batch/s, loss=0.241]\n",
      "  3%|▎         | 6/198 [00:00<00:03, 58.39batch/s, loss=0.201]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1992, Accuracy: 2104/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:03<00:00, 59.51batch/s, loss=0.177]\n",
      "  3%|▎         | 6/198 [00:00<00:03, 59.44batch/s, loss=0.147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1459, Accuracy: 2105/2115 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:03<00:00, 63.79batch/s, loss=0.132]\n",
      "  4%|▎         | 7/198 [00:00<00:03, 58.87batch/s, loss=0.115]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1096, Accuracy: 2106/2115 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:03<00:00, 59.86batch/s, loss=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0847, Accuracy: 2107/2115 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in (range(1, epochs + 1)):\n",
    "    train(model_01, device, train_loader_01, optimizer, epoch)\n",
    "    test(model_01, device, test_loader_01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonostante l'estrema semplicità del nostro modello siamo comunque riusciti a ottenere un'accuratezza >99% in pochi secondi (com'era prevedibile). Fin'ora siamo ben dentro il classico dominio del ML e non abbiamo visto niente di nuovo rispetto a una semplice introduzione alle basi delle reti neurali.\n",
    "Immaginiamo ora di voler ampliare lo spettro d'applicazione del nostro modello aggiungendo la possibilità di classificare una terza cifra, ovvero il numero 2.\n",
    "\n",
    "Considerando il fatto che possediamo ancora i dati relativi alle due cifre, ci limitiamo a eseguire nuovamente l'allenamento, aggiungendo al dataset le nuove immagini.\n",
    "\n",
    "Iniziamo ripetendo la procedura effettuata in precedenza per creare i dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5923, 1])\n",
      "torch.Size([6742, 1])\n",
      "torch.Size([5958, 1])\n",
      "torch.Size([18623, 1])\n",
      "torch.Size([980, 1])\n",
      "torch.Size([1135, 1])\n",
      "torch.Size([1032, 1])\n",
      "torch.Size([3147, 1])\n"
     ]
    }
   ],
   "source": [
    "idx_0 = train_dataset.targets == 0\n",
    "idx_1 = train_dataset.targets == 1\n",
    "idx_2 = train_dataset.targets == 2\n",
    "\n",
    "idx = idx_0 | idx_1 | idx_2\n",
    "\n",
    "print(idx_0.nonzero().shape)\n",
    "print(idx_1.nonzero().shape)\n",
    "print(idx_2.nonzero().shape)\n",
    "print(idx.nonzero().shape)\n",
    "\n",
    "train_dataset_012 = copy.deepcopy(train_dataset)\n",
    "train_dataset_012.targets = train_dataset_012.targets[idx]\n",
    "train_dataset_012.data = train_dataset_012.data[idx]\n",
    "\n",
    "train_loader_012 = torch.utils.data.DataLoader(train_dataset_012, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "idx_0 = test_dataset.targets == 0\n",
    "idx_1 = test_dataset.targets == 1\n",
    "idx_2 = test_dataset.targets == 2\n",
    "\n",
    "idx = idx_0 | idx_1 | idx_2\n",
    "\n",
    "print(idx_0.nonzero().shape)\n",
    "print(idx_1.nonzero().shape)\n",
    "print(idx_2.nonzero().shape)\n",
    "print(idx.nonzero().shape)\n",
    "\n",
    "test_dataset_012 = copy.deepcopy(test_dataset)\n",
    "test_dataset_012.targets = test_dataset_012.targets[idx]\n",
    "test_dataset_012.data = test_dataset_012.data[idx]\n",
    "\n",
    "test_loader_012 = torch.utils.data.DataLoader(test_dataset_012, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che il processo, già macchinoso la prima volta, diventa insostenibile qualora lo si dovesse scalare a grande scala. Appare evidente la necessità di creare un metodo più efficiente per caricare i dati in questo modo.\n",
    "\n",
    "Incappiamo ora in un secondo problema: il nostro modello possiede due soli neuroni in output. Occorre quindi **cambiare la topologia della rete neurale**, ovvero modificare il numero di neuroni in uno dei suoi strati, in questo caso l'ultimo. Come fare? Diversi approcci sono possibili. Il più semplice consiste nell'istanziare un nuovo modello avente il numero giusto di neuroni d'uscita. Tuttavia, così facendo si paga un costo enorme: perdiamo totalmente ogni contributo dato dal precedente allenamento. Alla fine dei conti, stiamo semplicemente ripetendo la procedura di addestramento *ex novo*, non usando i risultati ottenuti precedentemente. Ovviamente, questa tecnica \"assicura\" la risucita dell'addestramento, motivo per il quale è presa da riferimento con il quale valutare l'efficacia degli algoritmi di CL. Questo approccio è detto **incremental learning**, ovvero \"bariamo e riaddestriamo da zero\" (che è ciò che vogliamo evitare facendo CL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 71.72batch/s, loss=0.766]\n",
      "  2%|▏         | 7/291 [00:00<00:04, 64.86batch/s, loss=0.376]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3894, Accuracy: 2976/3147 (95%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 59.44batch/s, loss=0.239]\n",
      "  2%|▏         | 6/291 [00:00<00:04, 57.55batch/s, loss=0.161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1545, Accuracy: 3048/3147 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 51.42batch/s, loss=0.13] \n",
      "  2%|▏         | 6/291 [00:00<00:05, 53.88batch/s, loss=0.131]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1041, Accuracy: 3075/3147 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 45.49batch/s, loss=0.0988]\n",
      "  2%|▏         | 6/291 [00:00<00:05, 51.98batch/s, loss=0.105] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0833, Accuracy: 3085/3147 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 42.53batch/s, loss=0.0843]\n",
      "  2%|▏         | 5/291 [00:00<00:06, 45.59batch/s, loss=0.0724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0720, Accuracy: 3085/3147 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 52.42batch/s, loss=0.0754]\n",
      "  2%|▏         | 6/291 [00:00<00:04, 58.09batch/s, loss=0.0712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0647, Accuracy: 3092/3147 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 50.92batch/s, loss=0.0693]\n",
      "  2%|▏         | 6/291 [00:00<00:05, 53.83batch/s, loss=0.0622]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0595, Accuracy: 3096/3147 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 47.34batch/s, loss=0.0648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0546, Accuracy: 3101/3147 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet_again(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet_again, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x1 = F.relu(x)\n",
    "        x = self.fc2(x1)\n",
    "        x2 = F.relu(x)\n",
    "\n",
    "        return F.log_softmax(self.fc3(x2), dim=1)\n",
    "\n",
    "epochs      = 5\n",
    "lr          = 1e-2\n",
    "\n",
    "model_012 = SimpleNet_again().to(device)\n",
    "\n",
    "optimizer = optim.Adadelta(model_012.parameters(), lr = lr)\n",
    "\n",
    "for epoch in (range(1, epochs + 1)):\n",
    "    train(model_012, device, train_loader_012, optimizer, epoch)\n",
    "    test(model_012, device, test_loader_012)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima, anche qui otteniamo un risultato molto buono in poco tempo. Tuttavia non siamo soddisfatti. Per quanto funzionale (sulla nostra piccola e irrealistica scala), questo approccio è inefficiente, inelegante e difficilmente scalabile. Vogliamo trovare un modo di sfruttare l'addestramento precedente della rete neurale, in modo (si spera!) di aumentare le prestazioni. Un approccio sensato è quello di considerare come delle scatole nere tutto ciò che procede l'ultimo (o gli ultimi) strati della rete neurale: gli strati intermedi vengono detti \"estrattori di caratteristiche\" (features extractors), mentre gli ultimi vengono detti \"classificatori\". Ipersemplificando, i considera quindi l'insieme degli strati intermedi come una serie di applicazioni geometriche che trasformano gli input in una loro rappresentazione all'interno di uno spazio a dimensione differente, le cui caratteristiche metriche descrivono il \"grado di seprazione\" tra diversi sample mostrati in fase di addestramento. Lo strato di classificazione mappa questa rappresentazione sullo spazio di output.\n",
    "\n",
    "Si potrebbe quindi modificare solo il classificatore (strato finale), lasciando inalterato l'estrattore di feature. Così facendo abbiamo implicitamente assunto che la topologia dello spazio delle feature (ottenuta dagli stati intermedi) possa \"accomodare\" in maniera corretta e significativa i nuovi dati. Solo l'esperimento può dimostarcelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model_01_last_modified = copy.deepcopy(model_01)\n",
    "\n",
    "n_layers = len(list(model_01_last_modified.parameters()))\n",
    "\n",
    "for i,params in enumerate(model_01_last_modified.parameters()):\n",
    "    if i != n_layers - 1:\n",
    "        params.requires_grad = False\n",
    "\n",
    "for i,params in enumerate(model_01_last_modified.parameters()):\n",
    "    print(params.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "modules = model_01_last_modified._modules\n",
    "last_module_name = list(modules.keys())[-1]\n",
    "\n",
    "model_01_last_modified._modules[last_module_name] = nn.Linear(64,3)\n",
    "\n",
    "for child in model_01_last_modified.children():\n",
    "    print(child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 82.85batch/s, loss=1.16]\n",
      "  3%|▎         | 9/291 [00:00<00:03, 81.74batch/s, loss=1.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0766, Accuracy: 984/3147 (31%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 86.68batch/s, loss=0.996]\n",
      "  3%|▎         | 8/291 [00:00<00:03, 71.52batch/s, loss=0.913]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9262, Accuracy: 2109/3147 (67%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 84.62batch/s, loss=0.864]\n",
      "  3%|▎         | 8/291 [00:00<00:03, 77.88batch/s, loss=0.808]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8105, Accuracy: 2110/3147 (67%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 76.21batch/s, loss=0.765]\n",
      "  3%|▎         | 8/291 [00:00<00:03, 73.60batch/s, loss=0.727]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7236, Accuracy: 2143/3147 (68%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 75.85batch/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6554, Accuracy: 2265/3147 (72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs      = 5\n",
    "lr          = 1e-2\n",
    "\n",
    "optimizer = optim.Adadelta(model_01_last_modified.parameters(), lr = lr)\n",
    "\n",
    "for epoch in (range(1, epochs + 1)):\n",
    "    train(model_01_last_modified, device, train_loader_012, optimizer, epoch)\n",
    "    test(model_01_last_modified, device, test_loader_012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo brevemente che i layer intermedi non sono stati modificati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0\n",
      "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0\n"
     ]
    }
   ],
   "source": [
    "for original,modified in zip(model_01.parameters(), model_01_last_modified.parameters()):\n",
    "    try:\n",
    "        print(original == modified)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato ottenuto non è buono quanto il valore di riferimento. Probabilmente la cause è da ricercarsi nella semplicità del nostro modello, tuttavia questo approccio ha dei limiti intrinsechi: non è detto che lo spazio delle feature imparate su di un specifico insieme di dati sia \"valido\" anche per dati fuori dalla distribuzione originale. Questo approccio è alla base del cosiddetto **transfer learning**, che non approfondiamo in questa sede.\n",
    "\n",
    "Vogliamo però notare che abbiamo già ottenuto un piccolo vantaggio (nonostante un basso rendimento complessivo): la velocità del training è quasi raddoppiata, com'è ovvio considerando che stiamo aggiornando un sottoinsieme piuttosto piccolo di parametri.\n",
    "\n",
    "## 2 - Sviluppo\n",
    "\n",
    "### Accesso limitato ai dati\n",
    "\n",
    "Fin'ora abbiamo avuto un grande vantaggio: i dati a nostra disposizione rimanevano tali per sempre. A primo avviso può sembrare naturale, percezione data dalla relativa facilità di stoccaggio dei dati per progetti amatoriali. Tuttavia, il costo dello stoccaggio di dati non può essere trascurato in caso di modelli estremamente complessi. Dato che il valore del ML è direttamente proporzionale alla complessità dei problemi che permette di affrontare, è di fondamentale importanza comprendere l'alto costo dell'immagazzinamento dei dati. \n",
    "\n",
    "Ogni giorno, le decine di satelliti metereologici che orbitano intorno al nostro pianeta raccolgo TB di dati relativi alle condizioni fisiche e chimiche dell'atmosfera e della superficie del pianeta. La maggior parte di questi dati viene impiegata per eseguire delle previsioni metereologiche, tuttavia solo una parte piuttosto esigua viene immagazzinata con la risoluzione massima. La maggior parte dei dati viene salvata con una risoluzione spaziale nettamente inferiore. Vengono quindi perse immense quantità di dati ogni giorno, poichè il costo dell'immagazzinamento sarebbe proibitivo (e probabilmente l'output globale di memorie informatiche dovrebbe aumentare di molto per poter sostenere la richiesta, cosa ovvia impossibile).\n",
    "\n",
    "Immaginiamo di sviluppare un robot umanoide che debba interagire con gli umani e con l'ambiente circostante. Esso deve imparare tramite l'esperienza delle informazioni che non solo non sono conosciute a priori, ma non sono *conoscibili* a priori: l'ambiente è in perenne mutamento, così come gli oggetti e le interazioni tra essi. Risulta quindi essenziale una capacità di astrazione tale da permettere l'apprendimento e il riconoscimento in maniera continuativa (\"non si smette mai di imparare\"). Immaginiamo di dotare il nostro robot di un imput video composto da due telecamere (per avere il senso della profondità) aventi una risoluzione di 1080p (HD) operanti a 60 FPS: produrremmo svariate decine di GB al giorno solo di dati video (assumendo di usare compressione video). Diventerebbe presto impraticabile immagazzinare tutti i dati in locale (nel robot) e il costo (e l'efficienza) del sistema diminuirebbe piuttosto velocemente.\n",
    "\n",
    "Risulta evidente l'assoluta necessità di migliorare lo stato delle cose. D'ora in poi assumeremo che i dati di addestramento diventeranno *totalmente o quasi totalmente* indisponibili una volta usati per l'addestramento. \"Quasi totalmente\" è un riferimento ad alcune tecniche che prevedono il salvataggio di un numero molto limitato di esempi per ogni categoria.\n",
    "\n",
    "### Catastrophic forgetting\n",
    "\n",
    "Perchè non continuare semplicemente l'addestramento con i nuovi dati disponibili? In effetti, *a priori* non abbiamo nessun motivo **semplice** per pensare a una drastica riduzione delle performance se adottiamo tale linea di condotta. Un rapido esempio dimostrerà l'erroneità di tale pensiero.\n",
    "\n",
    "Continuiamo l'addestramento del nostro modello originale, dopo aver avuto cura di modificare l'ultimo strato per adattarlo alla presenza di una terza cifra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model_01_continue = copy.deepcopy(model_01)\n",
    "\n",
    "modules = model_01_continue._modules\n",
    "last_module_name = list(modules.keys())[-1]\n",
    "\n",
    "model_01_continue._modules[last_module_name] = nn.Linear(64,3)\n",
    "\n",
    "for child in model_01_continue.children():\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2 = train_dataset.targets == 2\n",
    "\n",
    "idx = idx_2\n",
    "\n",
    "train_dataset_2 = copy.deepcopy(train_dataset)\n",
    "train_dataset_2.targets = train_dataset_2.targets[idx]\n",
    "train_dataset_2.data = train_dataset_2.data[idx]\n",
    "\n",
    "train_loader_2 = torch.utils.data.DataLoader(train_dataset_2, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "idx_2 = test_dataset.targets == 2\n",
    "\n",
    "idx = idx_2\n",
    "\n",
    "test_dataset_2 = copy.deepcopy(test_dataset)\n",
    "test_dataset_2.targets = test_dataset_2.targets[idx]\n",
    "test_dataset_2.data = test_dataset_2.data[idx]\n",
    "\n",
    "test_loader_2 = torch.utils.data.DataLoader(test_dataset_2, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo il modello usando solo i dati relativi alla cifra 2, tuttavia eseguiamo il test anche ssu tutte e tre le cifre, per osservare quanto la prestazione risenta di questo tipo di addestramento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 75.60batch/s, loss=0.496]\n",
      "  9%|▊         | 8/94 [00:00<00:01, 74.52batch/s, loss=0.0916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9698, Accuracy: 1032/3147 (33%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 79.75batch/s, loss=0.0467]\n",
      "  9%|▊         | 8/94 [00:00<00:01, 75.59batch/s, loss=0.0159]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.1395, Accuracy: 1032/3147 (33%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 78.13batch/s, loss=0.00989]\n",
      "  9%|▊         | 8/94 [00:00<00:01, 74.33batch/s, loss=0.00512]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.9094, Accuracy: 1032/3147 (33%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 67.77batch/s, loss=0.00368]\n",
      "  7%|▋         | 7/94 [00:00<00:01, 68.26batch/s, loss=0.0023] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.4357, Accuracy: 1032/3147 (33%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 76.16batch/s, loss=0.00184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.8280, Accuracy: 1032/3147 (33%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs      = 5\n",
    "lr          = 1e-2\n",
    "\n",
    "optimizer = optim.Adadelta(model_01_continue.parameters(), lr = lr)\n",
    "\n",
    "for epoch in (range(1, epochs + 1)):\n",
    "    train(model_01_continue, device, train_loader_2, optimizer, epoch)\n",
    "    test(model_01_continue, device, test_loader_012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non a caso questo fenomeno viene detto **catastrophic forgetting**: il modello ha completamente disimparato a discernere le cifre tra di loro, risultando in un modello sostanzialmente casuale (e inutile). Questa è l'origine di tutti i mali del Continual Learning, il peccato originale di ogni tentavo di affrancamento dalla tirannia dei dataset statici. Questo fenomeno era immaginabile anche prima dell'esecuzione di questo semplice esperimento, pensando a cosa significa la procedura di addestramento di una rete neurale per discesa del gradiente: dato che il gradiente è essenzialmente lo stesso per ogni istanza delle immagini mostrate, i paramentri della rete si sono spostati tutti nella direzione che massimizza il guadagno sui dati presentati (questo è anche il motivo per cui è essenziale una buona randomizzazione degli input durante l'addestramneot durante il ML classico).\n",
    "\n",
    "Occore pensare a una mitigazione di questo effetto. Potremmo provare ad adottare una tecnica simile a quanto fatto in precedenza, ovvero fissare alcuni dei parametri in modo che non possano più essere cambiati. Tuttavia questo non cambierebbe il risultato finale: il classificatore \"imparerà\" comunque a riconoscere solamente gli ultimi dati forniti. Siamo però sulla strada giusta: il problema risiede, a quanto sembra, nella eccessiva \"mobilità\" del valore delle sinapsi. L'intuito ci suggerisce di trovare un modo di \"fissare\" i pesi in maniera che tuttavia siano sufficientemente mobili da poter continuare ad apprendere. Vorremmo quindi conferire una sorta di \"viscosità\" ai pesi, senza doverli fissare in maniera totale. Quale è tuttavia il giusto bilancio tra la stabilità e la plasticità dei pesi? In letteratura ci si riferisce a tale problema con la dizione \"stability-plasticity dilemma\" ed è uno dei nodi centrali della ricerca in ambito CL.\n",
    "\n",
    "## 3 - Automazione\n",
    "\n",
    "### Avalanche: and End-to-End library for Continual Learning\n",
    "\n",
    "*Nota: alcune parti di codice riportato di seguito provengono direttamente sito di Avalanche o dal repository ufficiale di Avalanche (https://github.com/ContinualAI/avalanche)*\n",
    "\n",
    "Prima di procedere con l'esplorazione di alcuni algoritmi di CL è opportuno avere un modo pe poter implementare le nostre idee ed eseguire i nostri esperimenti in maniera rapida, efficiente e riproducibile. La libreria Avalanche (https://avalanche.continualai.org/) rappresenta la risposta a questa esigenza. Essa presenta, oltre a un framework tale da permettere la comparazione tra diversi algoritmi pulita ed efficiente, l'implementazione di una vasta gamma di algoritmi pubblicati di CL. Impostiamo quindi un problema di CL: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience:  0\n",
      "Current Classes:  [4, 7]\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 0 (Task 0) from train stream --\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.01it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1959\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4176\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6766\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8692\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 45.90it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3150\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9597\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 56.29it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 4.7780\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 53.44it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.8128\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 56.58it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.6700\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 52.00it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.3938\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[   0,    0,    0,    0,  605,    0,    0,  375,    0,    0],\n",
      "        [   0,    0,    0,    0,  106,    0,    0, 1029,    0,    0],\n",
      "        [   0,    0,    0,    0,  725,    0,    0,  307,    0,    0],\n",
      "        [   0,    0,    0,    0,  352,    0,    0,  658,    0,    0],\n",
      "        [   0,    0,    0,    0,  951,    0,    0,   31,    0,    0],\n",
      "        [   0,    0,    0,    0,  414,    0,    0,  478,    0,    0],\n",
      "        [   0,    0,    0,    0,  909,    0,    0,   49,    0,    0],\n",
      "        [   0,    0,    0,    0,   50,    0,    0,  978,    0,    0],\n",
      "        [   0,    0,    0,    0,  524,    0,    0,  450,    0,    0],\n",
      "        [   0,    0,    0,    0,  709,    0,    0,  300,    0,    0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.9907\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1929\n",
      "Start of experience:  1\n",
      "Current Classes:  [0, 5]\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 1 (Task 0) from train stream --\n",
      "100%|██████████| 23/23 [00:01<00:00, 19.98it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8820\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4669\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4440\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8924\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 53.02it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9597\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.5051\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 52.76it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4205\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9204\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 51.68it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.7610\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 57.88it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.2522\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 53.25it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.7743\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[ 944,    0,    0,    0,    0,   36,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0, 1135,    0,    0,    0,    0],\n",
      "        [ 354,    0,    0,    0,    0,  678,    0,    0,    0,    0],\n",
      "        [ 166,    0,    0,    0,    0,  844,    0,    0,    0,    0],\n",
      "        [ 132,    0,    0,    0,    0,  850,    0,    0,    0,    0],\n",
      "        [ 113,    0,    0,    0,    0,  779,    0,    0,    0,    0],\n",
      "        [ 334,    0,    0,    0,    0,  624,    0,    0,    0,    0],\n",
      "        [ 121,    0,    0,    0,    0,  907,    0,    0,    0,    0],\n",
      "        [  65,    0,    0,    0,    0,  909,    0,    0,    0,    0],\n",
      "        [  79,    0,    0,    0,    0,  930,    0,    0,    0,    0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.3904\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.9597\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1723\n",
      "Start of experience:  2\n",
      "Current Classes:  [3, 6]\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 2 (Task 0) from train stream --\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.71it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9605\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3743\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4946\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9796\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 42.55it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9547\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.3645\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0050\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 44.98it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.9204\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.7218\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 52.45it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3009\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9822\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 53.62it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.8027\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 50.56it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.1646\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[   0,    0,    0,  612,    0,    0,  368,    0,    0,    0],\n",
      "        [   0,    0,    0, 1080,    0,    0,   55,    0,    0,    0],\n",
      "        [   0,    0,    0,  459,    0,    0,  573,    0,    0,    0],\n",
      "        [   0,    0,    0,  990,    0,    0,   20,    0,    0,    0],\n",
      "        [   0,    0,    0,  135,    0,    0,  847,    0,    0,    0],\n",
      "        [   0,    0,    0,  713,    0,    0,  179,    0,    0,    0],\n",
      "        [   0,    0,    0,   15,    0,    0,  943,    0,    0,    0],\n",
      "        [   0,    0,    0,  845,    0,    0,  173,   10,    0,    0],\n",
      "        [   0,    0,    0,  802,    0,    0,  172,    0,    0,    0],\n",
      "        [   0,    0,    0,  480,    0,    0,  529,    0,    0,    0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.6960\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.9376\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1943\n",
      "Start of experience:  3\n",
      "Current Classes:  [8, 1]\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 3 (Task 0) from train stream --\n",
      "100%|██████████| 26/26 [00:01<00:00, 19.48it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8656\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4968\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4542\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9140\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 46.74it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9408\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.4442\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0189\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 45.81it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.9161\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.6892\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0043\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 48.84it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.8440\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.9353\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1382\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 54.45it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4219\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9564\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 49.21it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.9913\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[   8,    6,    0,    0,    0,    0,   29,    0,  937,    0],\n",
      "        [   0, 1127,    0,    0,    0,    0,    0,    0,    8,    0],\n",
      "        [   0,  289,    0,    0,    0,    0,    3,    0,  740,    0],\n",
      "        [   0,   96,    0,    0,    0,    0,    0,    0,  914,    0],\n",
      "        [   0,  224,    0,    0,    0,    0,   36,    0,  722,    0],\n",
      "        [   0,  154,    0,    0,    0,    0,    0,    0,  738,    0],\n",
      "        [   1,  168,    0,    0,    0,    0,  272,    0,  517,    0],\n",
      "        [   0,  531,    0,    0,    0,    0,    2,   38,  457,    0],\n",
      "        [   0,   84,    0,    0,    0,    0,    0,    0,  890,    0],\n",
      "        [   0,  213,    0,    0,    0,    0,    2,    0,  794,    0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.2792\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.9003\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2335\n",
      "Start of experience:  4\n",
      "Current Classes:  [9, 2]\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 4 (Task 0) from train stream --\n",
      "100%|██████████| 24/24 [00:01<00:00, 19.56it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3890\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0975\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3175\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9312\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 50.15it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9587\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.3381\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0010\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 49.04it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.7847\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.3421\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1357\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 36.79it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.9096\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.0590\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0727\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 48.34it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp003 = 0.5609\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.5803\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3954\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 44.75it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9626\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9701\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[ 254,    0,  608,    8,    0,    0,   21,    0,   21,   68],\n",
      "        [   0,  834,  269,    0,    0,    0,    0,    0,    0,   32],\n",
      "        [   0,    1, 1013,    0,    0,    0,    1,    0,    0,   17],\n",
      "        [   0,    6,  616,   97,    0,    0,    0,    0,   18,  273],\n",
      "        [   0,    2,  147,    0,    0,    0,    3,    0,    0,  830],\n",
      "        [   0,   15,  366,   21,    0,    0,    0,    0,   35,  455],\n",
      "        [   1,    4,  852,    0,    0,    0,   46,    0,    0,   55],\n",
      "        [   2,   15,  129,    0,    0,    0,    1,    2,    0,  879],\n",
      "        [   0,    0,  626,    0,    0,    0,    0,    0,    0,  348],\n",
      "        [   0,    2,   39,    1,    0,    0,    0,    0,    0,  967]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.8434\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.8035\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3213\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics,\\\n",
    "    loss_metrics, timing_metrics, cpu_usage_metrics, StreamConfusionMatrix,\\\n",
    "    disk_usage_metrics, gpu_usage_metrics\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.strategies import Naive, Cumulative\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "scenario = SplitMNIST(n_experiences=5)\n",
    "\n",
    "# MODEL CREATION\n",
    "model = SimpleMLP(num_classes=scenario.n_classes)\n",
    "\n",
    "# DEFINE THE EVALUATION PLUGIN and LOGGERS\n",
    "# The evaluation plugin manages the metrics computation.\n",
    "# It takes as argument a list of metrics, collectes their results and returns \n",
    "# them to the strategy it is attached to.\n",
    "\n",
    "# log to Tensorboard\n",
    "tb_logger = TensorboardLogger()\n",
    "\n",
    "# log to text file\n",
    "text_logger = TextLogger(open('log.txt', 'w'))\n",
    "\n",
    "# print to stdout\n",
    "interactive_logger = InteractiveLogger()\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    StreamConfusionMatrix(num_classes=scenario.n_classes, save_image=False),\n",
    "    loggers=[interactive_logger, text_logger, tb_logger]\n",
    ")\n",
    "\n",
    "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
    "cl_strategy = Naive(\n",
    "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,\n",
    "    evaluator=eval_plugin)\n",
    "\n",
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in scenario.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "\n",
    "    # train returns a dictionary which contains all the metric values\n",
    "    res = cl_strategy.train(experience, num_workers=4)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    # eval also returns a dictionary which contains all the metric values\n",
    "    results.append(cl_strategy.eval(scenario.test_stream, num_workers=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Top1_Acc_MB/train_phase/train_stream/Task000', 'Loss_MB/train_phase/train_stream/Task000', 'Top1_Acc_Epoch/train_phase/train_stream/Task000', 'Loss_Epoch/train_phase/train_stream/Task000', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000', 'Loss_Exp/eval_phase/test_stream/Task000/Exp000', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001', 'Loss_Exp/eval_phase/test_stream/Task000/Exp001', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002', 'Loss_Exp/eval_phase/test_stream/Task000/Exp002', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003', 'Loss_Exp/eval_phase/test_stream/Task000/Exp003', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004', 'Loss_Exp/eval_phase/test_stream/Task000/Exp004', 'Top1_Acc_Stream/eval_phase/test_stream/Task000', 'Loss_Stream/eval_phase/test_stream/Task000', 'StreamForgetting/eval_phase/test_stream', 'ConfusionMatrix_Stream/eval_phase/test_stream'])\n",
      "tensor([[   0,    0,    0,    0,  605,    0,    0,  375,    0,    0],\n",
      "        [   0,    0,    0,    0,  106,    0,    0, 1029,    0,    0],\n",
      "        [   0,    0,    0,    0,  725,    0,    0,  307,    0,    0],\n",
      "        [   0,    0,    0,    0,  352,    0,    0,  658,    0,    0],\n",
      "        [   0,    0,    0,    0,  951,    0,    0,   31,    0,    0],\n",
      "        [   0,    0,    0,    0,  414,    0,    0,  478,    0,    0],\n",
      "        [   0,    0,    0,    0,  909,    0,    0,   49,    0,    0],\n",
      "        [   0,    0,    0,    0,   50,    0,    0,  978,    0,    0],\n",
      "        [   0,    0,    0,    0,  524,    0,    0,  450,    0,    0],\n",
      "        [   0,    0,    0,    0,  709,    0,    0,  300,    0,    0]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results[0].keys())\n",
    "print(results[0]['ConfusionMatrix_Stream/eval_phase/test_stream'])\n",
    "\n",
    "for r in results:\n",
    "    plt.imshow(r['ConfusionMatrix_Stream/eval_phase/test_stream'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
